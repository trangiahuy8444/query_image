(reltr2)➜  neo4j git:(main) python metrics.py 
Using device: cpu
/Users/huytran/miniforge3/envs/reltr2/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/Users/huytran/miniforge3/envs/reltr2/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Model loaded on CPU

Testing on 3 sample images...

Processing image: 1159285.jpg
Predicting on cpu
Image size: (1024, 768)
Input tensor shape: torch.Size([1, 3, 800, 1066])
Model outputs keys: dict_keys(['pred_logits', 'pred_boxes', 'sub_logits', 'sub_boxes', 'obj_logits', 'obj_boxes', 'rel_logits'])
Probas shapes: rel=torch.Size([200, 51]), sub=torch.Size([200, 151]), obj=torch.Size([200, 151])
Number of predictions kept: 6
Bbox shapes: sub=torch.Size([6, 4]), obj=torch.Size([6, 4])
Number of top-k predictions: 6
Prediction: laptop - on - table
Prediction: laptop - on - table
Prediction: cup - on - desk
Prediction: chair - under - desk
Prediction: laptop - on - table
Prediction: chair - under - desk
Total predictions: 6
Number of predictions: 6
Number of ground truth relationships: 0
Traceback (most recent call last):
  File "/Users/huytran/Library/CloudStorage/OneDrive-HochiminhCityUniversityofEducation/Developer/neo4j/metrics.py", line 315, in <module>
    test_results = test_sample_images(sample_image_ids)
  File "/Users/huytran/Library/CloudStorage/OneDrive-HochiminhCityUniversityofEducation/Developer/neo4j/metrics.py", line 281, in test_sample_images
    metrics = calculate_metrics(predictions, ground_truth)
  File "/Users/huytran/Library/CloudStorage/OneDrive-HochiminhCityUniversityofEducation/Developer/neo4j/metrics.py", line 35, in calculate_metrics
    auc_roc = auc(*roc_curve(y_true, y_scores)[:2])
  File "/Users/huytran/miniforge3/envs/reltr2/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 216, in wrapper
    return func(*args, **kwargs)
  File "/Users/huytran/miniforge3/envs/reltr2/lib/python3.9/site-packages/sklearn/metrics/_ranking.py", line 1150, in roc_curve
    fps, tps, thresholds = _binary_clf_curve(
  File "/Users/huytran/miniforge3/envs/reltr2/lib/python3.9/site-packages/sklearn/metrics/_ranking.py", line 820, in _binary_clf_curve
    check_consistent_length(y_true, y_score, sample_weight)
  File "/Users/huytran/miniforge3/envs/reltr2/lib/python3.9/site-packages/sklearn/utils/validation.py", line 475, in check_consistent_length
    raise ValueError(
ValueError: Found input variables with inconsistent numbers of samples: [3, 6]
(reltr2)➜  neo4j git:(main) 